{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biclustering documents with the Spectral Co-clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, SpectralCoclustering\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.cluster import v_measure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_normalizer(tokens):\n",
    "    \"\"\"\n",
    "    모든 숫자 토큰을 placehoder에 매핑한다.\n",
    "    많은 application에서 숫자로 시작하는 토근은 직접적으로 유용하지는 않지만 토큰이 존재한다는 사실이 관련될 수는 있다.\n",
    "    이러한 형태의 차원 감소를 적용함으로 일부 방법은 더 나은 성능을 발휘할 수 있다.\n",
    "    \"\"\"\n",
    "    return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing...\n",
      "Coclustering...\n",
      "Done in 0.54s. V-measure: 0.4487\n",
      "MiniBatchKmeans...\n",
      "Done in 1.95s. V-measure: 0.2690\n"
     ]
    }
   ],
   "source": [
    "class NumberNormalizingVectorizer(TfidfVectorizer):\n",
    "    def build_tokenizer(self):\n",
    "        tokenize = super().build_tokenizer()\n",
    "        return lambda doc: list(number_normalizer(tokenize(doc)))\n",
    "    \n",
    "# comp.os.ms-windows.misc 제외\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"comp.graphics\",\n",
    "    \"comp.sys.ibm.pc.hardware\",\n",
    "    \"comp.sys.mac.hardware\",\n",
    "    \"comp.windows.x\",\n",
    "    \"misc.forsale\",\n",
    "    \"rec.autos\",\n",
    "    \"rec.motorcycles\",\n",
    "    \"rec.sport.baseball\",\n",
    "    \"rec.sport.hockey\",\n",
    "    \"sci.crypt\",\n",
    "    \"sci.electronics\",\n",
    "    \"sci.med\",\n",
    "    \"sci.space\",\n",
    "    \"soc.religion.christian\",\n",
    "    \"talk.politics.mideast\",\n",
    "    \"talk.politics.misc\",\n",
    "    \"talk.religion.misc\",\n",
    "]\n",
    "newsgroups = fetch_20newsgroups(categories=categories)\n",
    "y_true = newsgroups.target\n",
    "\n",
    "vectorizer = NumberNormalizingVectorizer(stop_words=\"english\", min_df=5)\n",
    "cocluster = SpectralCoclustering(\n",
    "    n_clusters=len(categories), svd_method=\"arpack\", random_state=0\n",
    ")\n",
    "kmeans = MiniBatchKMeans(\n",
    "    n_clusters=len(categories), batch_size=20000, random_state=0, n_init=3\n",
    ")\n",
    "\n",
    "print(\"Vectorizing...\")\n",
    "X = vectorizer.fit_transform(newsgroups.data)\n",
    "\n",
    "print(\"Coclustering...\")\n",
    "start_time = time()\n",
    "cocluster.fit(X)\n",
    "y_cocluster = cocluster.row_labels_\n",
    "print(\n",
    "    \"Done in {:.2f}s. V-measure: {:.4f}\".format(time() - start_time, v_measure_score(y_cocluster, y_true))\n",
    ")\n",
    "\n",
    "print(\"MiniBatchKmeans...\")\n",
    "start_time = time()\n",
    "y_kemans = kmeans.fit_predict(X)\n",
    "print(\n",
    "     \"Done in {:.2f}s. V-measure: {:.4f}\".format(time() - start_time, v_measure_score(y_kemans, y_true))\n",
    ")\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "document_names = list(newsgroups.target_names[i] for i in newsgroups.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bicluster_ncut(i):\n",
    "    rows, cols = cocluster.get_indices(i)\n",
    "    if not (np.any(rows) and np.any(cols)):\n",
    "        import sys\n",
    "\n",
    "        return sys.float_info.max\n",
    "    row_complement = np.nonzero(np.logical_not(cocluster.rows_[i]))[0]\n",
    "    col_complement = np.nonzero(np.logical_not(cocluster.columns_[i]))[0]\n",
    "    # X[rows[:, np.newaxis], cols].sum()이 scipy <= 0.16  \n",
    "    weight = X[rows][:, cols].sum()\n",
    "    cut = X[row_complement][:, cols].sum() + X[rows][:, col_complement].sum()\n",
    "    return cut / weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best biclusters:\n",
      "----------------\n",
      "bicluster 0 : 8 documents, 6 words\n",
      "categories   : 100% talk.politics.mideast\n",
      "words        : cosmo, angmar, alfalfa, alphalpha, proline, benson\n",
      "\n",
      "bicluster 1 : 1092 documents, 2929 words\n",
      "categories   : 30% talk.politics.mideast, 27% soc.religion.christian, 26% alt.atheism\n",
      "words        : god, jesus, christians, atheists, morality, kent, sin, belief, objective, resurrection\n",
      "\n",
      "bicluster 2 : 2225 documents, 2862 words\n",
      "categories   : 18% comp.sys.mac.hardware, 16% comp.sys.ibm.pc.hardware, 16% sci.electronics\n",
      "words        : voltage, shipping, receiver, circuit, compression, digital, processing, scope, baalke, package\n",
      "\n",
      "bicluster 3 : 1505 documents, 3837 words\n",
      "categories   : 24% talk.politics.misc, 18% sci.med, 17% soc.religion.christian\n",
      "words        : geb, banks, gordon, drugs, kaldis, dyer, br, surrender, noring, n3jxp\n",
      "\n",
      "bicluster 4 : 1722 documents, 2666 words\n",
      "categories   : 27% rec.motorcycles, 23% rec.autos, 13% misc.forsale\n",
      "words        : bike, car, dod, ride, motorcycle, engine, bikes, bmw, helmet, cars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def most_common(d):\n",
    "    \"\"\"\n",
    "    가장 높은 값을 가진 defaultdict(int)의 항목이다.\n",
    "    Python >= 2.7에서 Counter.most_common과 비슷하다.\n",
    "    \"\"\"    \n",
    "    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "bicluster_ncuts = list(bicluster_ncut(i) for i in range(len(newsgroups.target_names)))\n",
    "best_idx = np.argsort(bicluster_ncuts)[:5]\n",
    "\n",
    "print()\n",
    "print(\"Best biclusters:\")\n",
    "print(\"----------------\")\n",
    "for idx, cluster in enumerate(best_idx):\n",
    "    n_rows, n_cols = cocluster.get_shape(cluster)\n",
    "    cluster_docs, cluster_words = cocluster.get_indices(cluster)\n",
    "    if not len(cluster_docs) or not len(cluster_words):\n",
    "        continue\n",
    "\n",
    "    # categories\n",
    "    counter = defaultdict(int)\n",
    "    for i in cluster_docs:\n",
    "        counter[document_names[i]] += 1\n",
    "    cat_string = \", \".join(\n",
    "        \"{:.0f}% {}\".format(float(c) / n_rows * 100, name)\n",
    "        for name, c in most_common(counter)[:3]\n",
    "    )\n",
    "\n",
    "    # words\n",
    "    out_of_cluster_docs = cocluster.row_labels_ != cluster\n",
    "    out_of_cluster_docs = np.where(out_of_cluster_docs)[0]\n",
    "    word_col = X[:, cluster_words]\n",
    "    word_scores = np.array(\n",
    "        word_col[cluster_docs, :].sum(axis=0)\n",
    "        - word_col[out_of_cluster_docs, :].sum(axis=0)\n",
    "    )\n",
    "    word_scores = word_scores.ravel()\n",
    "    important_words = list(\n",
    "        feature_names[cluster_words[i]] for i in word_scores.argsort()[:-11:-1]\n",
    "    )\n",
    "\n",
    "    print(\"bicluster {} : {} documents, {} words\".format(idx, n_rows, n_cols))\n",
    "    print(\"categories   : {}\".format(cat_string))\n",
    "    print(\"words        : {}\\n\".format(\", \".join(important_words)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
