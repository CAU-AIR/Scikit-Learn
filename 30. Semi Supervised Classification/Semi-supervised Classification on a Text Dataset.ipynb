{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Classification on a Text Dataset\n",
    "- semi-supervised 분류기는 20개의 뉴스 그룹 데이터 세트에 대해 학습\n",
    "    - 데이터세 로더에 이름을 지정하여 카테고리 수 조정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.semi_supervised import LabelSpreading, SelfTrainingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823 documents\n",
      "5 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 처음 5개의 카테고리가 포함된 데이터셋 로드\n",
    "data = fetch_20newsgroups(\n",
    "    subset=\"train\",\n",
    "    categories=[\n",
    "        \"alt.atheism\",\n",
    "        \"comp.graphics\",\n",
    "        \"comp.os.ms-windows.misc\",\n",
    "        \"comp.sys.ibm.pc.hardware\",\n",
    "        \"comp.sys.mac.hardware\",\n",
    "    ],\n",
    ")\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터들\n",
    "sdg_params = dict(alpha=1e-5, penalty=\"l2\", loss=\"log_loss\")\n",
    "vectorizer_params = dict(ngram_range=(1, 2), min_df=5, max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감독 파이프라인\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", SGDClassifier(**sdg_params)),\n",
    "    ]\n",
    ")\n",
    "# 셀프 트레이닝 파이프라인\n",
    "st_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", SelfTrainingClassifier(SGDClassifier(**sdg_params), verbose=True)),\n",
    "    ]\n",
    ")\n",
    "# 라벨 확산 파이프라인\n",
    "ls_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(**vectorizer_params)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        # LabelSpreading은 고밀도 행렬 지원하지 않음\n",
    "        (\"toarray\", FunctionTransformer(lambda x: x.toarray())),\n",
    "        (\"clf\", LabelSpreading()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"Number of training samples:\", len(X_train))\n",
    "    print(\"Unlabeled samples in training set:\", sum(1 for x in y_train if x == -1))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\n",
    "        \"Micro-averaged F1 score on test set: %0.3f\"\n",
    "        % f1_score(y_test, y_pred, average=\"micro\")\n",
    "    )\n",
    "    print(\"-\" * 10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised SGDClassifier on 100% of the data:\n",
      "Number of training samples: 2117\n",
      "Unlabeled samples in training set: 0\n",
      "Micro-averaged F1 score on test set: 0.911\n",
      "----------\n",
      "\n",
      "Supervised SGDClassifier on 20% of the training data:\n",
      "Number of training samples: 405\n",
      "Unlabeled samples in training set: 0\n",
      "Micro-averaged F1 score on test set: 0.776\n",
      "----------\n",
      "\n",
      "SelfTrainingClassifier on 20% of the training data (rest is unlabeled):\n",
      "Number of training samples: 2117\n",
      "Unlabeled samples in training set: 1712\n",
      "End of iteration 1, added 1047 new labels.\n",
      "End of iteration 2, added 249 new labels.\n",
      "End of iteration 3, added 67 new labels.\n",
      "End of iteration 4, added 25 new labels.\n",
      "End of iteration 5, added 14 new labels.\n",
      "End of iteration 6, added 8 new labels.\n",
      "End of iteration 7, added 6 new labels.\n",
      "End of iteration 8, added 2 new labels.\n",
      "End of iteration 9, added 1 new labels.\n",
      "End of iteration 10, added 2 new labels.\n",
      "Micro-averaged F1 score on test set: 0.841\n",
      "----------\n",
      "\n",
      "LabelSpreading on 20% of the data (rest is unlabeled):\n",
      "Number of training samples: 2117\n",
      "Unlabeled samples in training set: 1712\n",
      "Micro-averaged F1 score on test set: 0.666\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X, y = data.data, data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    print(\"Supervised SGDClassifier on 100% of the data:\")\n",
    "    eval_and_print_metrics(pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # 훈련 데이터셋의 20% 마스크 선택\n",
    "    y_mask = np.random.rand(len(y_train)) < 0.2\n",
    "\n",
    "    # X_20 및 y_20은 마스크로 표시된 열차 데이터셋의 하위 집합 \n",
    "    X_20, y_20 = map(\n",
    "        list, zip(*((x, y) for x, y, m in zip(X_train, y_train, y_mask) if m))\n",
    "    )\n",
    "    print(\"Supervised SGDClassifier on 20% of the training data:\")\n",
    "    eval_and_print_metrics(pipeline, X_20, y_20, X_test, y_test)\n",
    "\n",
    "    # 마스크 되지 않은 하위 집합을 레이블이 해제되도록 설정\n",
    "    y_train[~y_mask] = -1\n",
    "    print(\"SelfTrainingClassifier on 20% of the training data (rest is unlabeled):\")\n",
    "    eval_and_print_metrics(st_pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    print(\"LabelSpreading on 20% of the data (rest is unlabeled):\")\n",
    "    eval_and_print_metrics(ls_pipeline, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
