{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# different learning rate schedules and momentum parameters\n",
    "params = [\n",
    "    {\n",
    "        \"solver\": \"sgd\",\n",
    "        \"learning_rate\": \"constant\",\n",
    "        \"momentum\": 0,\n",
    "        \"learning_rate_init\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"solver\": \"sgd\",\n",
    "        \"learning_rate\": \"constant\",\n",
    "        \"momentum\": 0.9,\n",
    "        \"nesterovs_momentum\": False,\n",
    "        \"learning_rate_init\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"solver\": \"sgd\",\n",
    "        \"learning_rate\": \"constant\",\n",
    "        \"momentum\": 0.9,\n",
    "        \"nesterovs_momentum\": True,\n",
    "        \"learning_rate_init\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"solver\": \"sgd\",\n",
    "        \"learning_rate\": \"invscaling\",\n",
    "        \"momentum\": 0,\n",
    "        \"learning_rate_init\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"solver\": \"sgd\",\n",
    "        \"learning_rate\": \"invscaling\",\n",
    "        \"momentum\": 0.9,\n",
    "        \"nesterovs_momentum\": False,\n",
    "        \"learning_rate_init\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"solver\": \"sgd\",\n",
    "        \"learning_rate\": \"invscaling\",\n",
    "        \"momentum\": 0.9,\n",
    "        \"nesterovs_momentum\": True,\n",
    "        \"learning_rate_init\": 0.2,\n",
    "    },\n",
    "    {\"solver\": \"adam\", \"learning_rate_init\": 0.01},\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    # 각 설정에 대한 라벨\n",
    "    \"constant learning-rate\",\n",
    "    \"constant with momentum\",\n",
    "    \"constant with Nesterov's momentum\",\n",
    "    \"inv-scaling learning-rate\",\n",
    "    \"inv-scaling with momentum\",\n",
    "    \"inv-scaling with Nesterov's momentum\",\n",
    "    \"adam\",\n",
    "]\n",
    "\n",
    "plot_args = [\n",
    "    # 각 그래프에 대한 스타일 설정\n",
    "    {\"c\": \"red\", \"linestyle\": \"-\"},\n",
    "    {\"c\": \"green\", \"linestyle\": \"-\"},\n",
    "    {\"c\": \"blue\", \"linestyle\": \"-\"},\n",
    "    {\"c\": \"red\", \"linestyle\": \"--\"},\n",
    "    {\"c\": \"green\", \"linestyle\": \"--\"},\n",
    "    {\"c\": \"blue\", \"linestyle\": \"--\"},\n",
    "    {\"c\": \"black\", \"linestyle\": \"-\"},\n",
    "]\n",
    "\n",
    "# 데이터셋별로 결과를 시각화하는 함수\n",
    "def plot_on_dataset(X, y, ax, name):\n",
    "    # 각 데이터셋에 대해, 모든 학습 전략에 대한 학습을 시각화한다\n",
    "    print(\"\\nlearning on dataset %s\" % name)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    # 데이터 전처리: 스케일링\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    mlps = []\n",
    "    # 데이터셋의 크기에 따라 최대 반복 횟수를 설정\n",
    "    if name == \"digits\":\n",
    "        max_iter = 15  # 숫자 데이터셋은 크기가 크지만 빠르게 수렴한다\n",
    "    else:\n",
    "        max_iter = 400\n",
    "\n",
    "    # 각 매개변수 설정에 대해 MLPClassifier를 훈련\n",
    "    for label, param in zip(labels, params):\n",
    "        print(\"training: %s\" % label)\n",
    "        mlp = MLPClassifier(random_state=0, max_iter=max_iter, **param)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            # 수렴 경고를 무시\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\", category=ConvergenceWarning, module=\"sklearn\"\n",
    "            )\n",
    "            mlp.fit(X, y)\n",
    "\n",
    "        mlps.append(mlp)\n",
    "        print(\"Training set score: %f\" % mlp.score(X, y))\n",
    "        print(\"Training set loss: %f\" % mlp.loss_)\n",
    "    # 각 MLP 모델의 손실 곡선을 그린다\n",
    "    for mlp, label, args in zip(mlps, labels, plot_args):\n",
    "        ax.plot(mlp.loss_curve_, label=label, **args)\n",
    "\n",
    "\n",
    "# 2x2 서브플롯에서 각각의 데이터셋에 대한 학습 곡선을 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "# 네 가지 데이터셋을 로드\n",
    "iris = datasets.load_iris()\n",
    "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "data_sets = [\n",
    "    (iris.data, iris.target),\n",
    "    (X_digits, y_digits),\n",
    "    datasets.make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "    datasets.make_moons(noise=0.3, random_state=0),\n",
    "]\n",
    "\n",
    "# 각 데이터셋에 대해 시각화 실행\n",
    "for ax, data, name in zip(\n",
    "    axes.ravel(), data_sets, [\"iris\", \"digits\", \"circles\", \"moons\"]\n",
    "):\n",
    "    plot_on_dataset(*data, ax=ax, name=name)\n",
    "\n",
    "# 범례를 추가하고 그래프를 표시\n",
    "fig.legend(ax.get_lines(), labels, ncol=3, loc=\"upper center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
